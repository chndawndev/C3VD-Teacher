{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc91d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:4\n",
      "RAW_ROOT    : /data1_ycao/chua/projects/cdTeacher/data_raw/c1_descending_t2_v2\n",
      "STAGE_A_ROOT: /data1_ycao/chua/projects/cdTeacher/outputs/stage_A/c1_descending_t2_v2\n",
      "NS_CONFIG   : /data1_ycao/chua/projects/cdTeacher/outputs/stage_A/c1_descending_t2_v2/outputs/nerfacto/2025-11-16_042345/config.yml\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\"\"\"\n",
    "Stage D: NeRF vs GT geometry evaluation\n",
    "Sequence: c1_descending_t2_v2\n",
    "\n",
    "依赖前置：\n",
    "- Stage A 已经生成：\n",
    "  - undistorted/rgb/*.png\n",
    "  - camera_pinhole.json\n",
    "  - transforms.json\n",
    "- Nerfstudio 已经训练完一个 run：\n",
    "  - 有对应的 config.yml（ns-train 输出目录）\n",
    "- C3VDv2 raw 目录下有 coverage_mesh.obj\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import open3d as o3d\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "\n",
    "device = \"cuda\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# %% [markdown]\n",
    "# ----\n",
    "# ## D0. 配置路径（***请根据你自己的目录检查一下***）\n",
    "\n",
    "# %%\n",
    "SEQ = \"c1_descending_t2_v2\"\n",
    "\n",
    "PROJECT_ROOT = Path(\"/data1_ycao/chua/projects/cdTeacher\")\n",
    "RAW_ROOT     = PROJECT_ROOT / \"data_raw\" / SEQ\n",
    "STAGE_A_ROOT = PROJECT_ROOT / \"outputs\" / \"stage_A\" / SEQ\n",
    "\n",
    "# Nerfstudio run 的 config.yml 路径（请改成你真实的路径）\n",
    "# 例子：/data1_ycao/chua/projects/cdTeacher/outputs/nerfstudio_runs/c3vdv2_multi_seq_c1_descending_t2_v2/nerfacto/2025-11-18_12-34-56/config.yml\n",
    "NS_CONFIG_PATH = Path(\n",
    "    \"/data1_ycao/chua/projects/cdTeacher/outputs/stage_A/c1_descending_t2_v2/outputs/nerfacto/2025-11-16_042345/config.yml\"\n",
    ")\n",
    "\n",
    "assert RAW_ROOT.exists(), f\"RAW_ROOT not found: {RAW_ROOT}\"\n",
    "assert STAGE_A_ROOT.exists(), f\"STAGE_A_ROOT not found: {STAGE_A_ROOT}\"\n",
    "assert NS_CONFIG_PATH.exists(), f\"NS_CONFIG_PATH not found: {NS_CONFIG_PATH}\"\n",
    "\n",
    "print(\"RAW_ROOT    :\", RAW_ROOT)\n",
    "print(\"STAGE_A_ROOT:\", STAGE_A_ROOT)\n",
    "print(\"NS_CONFIG   :\", NS_CONFIG_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2ac77f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinhole intrinsics: {'width': 960, 'height': 720, 'fx': 480.00000000000006, 'fy': 480.00000000000006, 'cx': 480.0, 'cy': 360.0, 'fov_deg': 90.0}\n",
      "Num frames in transforms: 617\n",
      "poses_c2w: torch.Size([617, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ----\n",
    "# ## D1. 读取 pinhole 相机和 transforms.json\n",
    "\n",
    "# %%\n",
    "# camera_pinhole.json\n",
    "with open(STAGE_A_ROOT / \"undistorted\" / \"camera_pinhole.json\", \"r\") as f:\n",
    "    cam_pinhole = json.load(f)\n",
    "\n",
    "W_p = cam_pinhole[\"width\"]\n",
    "H_p = cam_pinhole[\"height\"]\n",
    "fx  = cam_pinhole[\"fx\"]\n",
    "fy  = cam_pinhole[\"fy\"]\n",
    "cx  = cam_pinhole[\"cx\"]\n",
    "cy  = cam_pinhole[\"cy\"]\n",
    "\n",
    "print(\"Pinhole intrinsics:\", cam_pinhole)\n",
    "\n",
    "# transforms.json\n",
    "with open(STAGE_A_ROOT / \"transforms.json\", \"r\") as f:\n",
    "    tf_meta = json.load(f)\n",
    "\n",
    "frames = tf_meta[\"frames\"]\n",
    "num_frames = len(frames)\n",
    "print(\"Num frames in transforms:\", num_frames)\n",
    "\n",
    "# 取出所有 T_cam2world\n",
    "poses_c2w = np.stack([np.array(fr[\"transform_matrix\"], dtype=np.float32) for fr in frames], axis=0)\n",
    "poses_c2w = torch.from_numpy(poses_c2w).to(device)  # (N,4,4)\n",
    "print(\"poses_c2w:\", poses_c2w.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "629686d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth output dir: /data1_ycao/chua/projects/cdTeacher/outputs/stage_D/c1_descending_t2_v2/ns_depth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ----\n",
    "# ## D2. 用 Nerfstudio 渲染 depth（世界坐标下的表面）\n",
    "\n",
    "# 这里我们用 ns-render CLI，让 Nerfstudio 输出 per-frame depth 图像。\n",
    "\n",
    "# %%\n",
    "NS_DEPTH_ROOT = \"/data1_ycao/chua/projects/cdTeacher/outputs/stage_D/c1_descending_t2_v2/ns_depth\"\n",
    "# NS_DEPTH_ROOT.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(\"Depth output dir:\", NS_DEPTH_ROOT)\n",
    "\n",
    "\n",
    "# 运行 ns-render 生成 depth 图像。\n",
    "# 注意：\n",
    "# - 需要在 nerfstudio 环境中运行此 cell（或者在 shell 里先手动跑一遍 ns-render）。\n",
    "# - rendered_image_type 里至少包含 depth。\n",
    "# - 这里假设 ns-render 能自动读取 NerfstudioData 格式的 transforms.json。\n",
    "\n",
    "\n",
    "# CONFIG=/data1_ycao/chua/projects/cdTeacher/outputs/stage_A/c1_descending_t2_v2/outputs/nerfacto/2025-11-16_042345/config.yml\n",
    "# OUT_DIR=/data1_ycao/chua/projects/cdTeacher/outputs/stage_D/c1_descending_t2_v2/ns_depth\n",
    "# mkdir -p \"$OUT_DIR\"\n",
    "# ns-render dataset \\\n",
    "#   --load-config \"$CONFIG\" \\\n",
    "#   --output-path \"$OUT_DIR\" \\\n",
    "#   --image-format png \\\n",
    "#   --rendered-output-names depth\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66129c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth_dir: /data1_ycao/chua/projects/cdTeacher/outputs/stage_D/c1_descending_t2_v2/ns_depth/test/depth exists: True\n",
      "Sample depth files: ['0010.png', '0020.png', '0030.png', '0040.png', '0050.png']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# 跑完之后，NS_DEPTH_ROOT 中应该有若干 `depth/****.png` 或 `.exr`。\n",
    "# 我们假设保存为 16-bit PNG 格式的深度（单位：米）。\n",
    "# 如果格式不同，请根据实际情况做转换。\n",
    "\n",
    "# %%\n",
    "# 检查一下 depth 目录\n",
    "depth_dir = Path(NS_DEPTH_ROOT + \"/test/depth\")\n",
    "print(\"depth_dir:\", depth_dir, \"exists:\", depth_dir.exists())\n",
    "if depth_dir.exists():\n",
    "    some = sorted(depth_dir.glob(\"*.png\"))[:5]\n",
    "    print(\"Sample depth files:\", [p.name for p in some])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034566ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dirs_cam_pinhole: torch.Size([720, 960, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collect NeRF points:   0%|          | 0/617 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collect NeRF points:   2%|▏         | 10/617 [00:00<00:09, 66.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: dirs_valid shape: torch.Size([2073600])\n",
      "DEBUG: d_valid shape before: torch.Size([2073600])\n",
      "DEBUG: d_valid unsqueezed: torch.Size([2073600, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 16018.07 GiB. GPU 4 has a total capacty of 47.41 GiB of which 46.82 GiB is free. Including non-PyTorch memory, this process has 594.00 MiB memory in use. Of the allocated memory 86.11 MiB is allocated by PyTorch, and 15.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 81\u001b[0m\n\u001b[1;32m     79\u001b[0m max_frames \u001b[38;5;241m=\u001b[39m num_frames  \u001b[38;5;66;03m# 或先 100\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fid \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(max_frames), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCollect NeRF points\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 81\u001b[0m     pts_w \u001b[38;5;241m=\u001b[39m \u001b[43mnerf_points_world_from_depth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pts_w \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[32], line 59\u001b[0m, in \u001b[0;36mnerf_points_world_from_depth\u001b[0;34m(frame_id, max_points)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEBUG: d_valid shape before: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00md_valid\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEBUG: d_valid unsqueezed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00md_valid\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 59\u001b[0m pts_cam \u001b[38;5;241m=\u001b[39m \u001b[43mdirs_valid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43md_valid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m         \u001b[38;5;66;03m# (Nv,3)\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# cam2world pose\u001b[39;00m\n\u001b[1;32m     62\u001b[0m T_c2w \u001b[38;5;241m=\u001b[39m poses_c2w[frame_id]                          \u001b[38;5;66;03m# (4,4)\u001b[39;00m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 16018.07 GiB. GPU 4 has a total capacty of 47.41 GiB of which 46.82 GiB is free. Including non-PyTorch memory, this process has 594.00 MiB memory in use. Of the allocated memory 86.11 MiB is allocated by PyTorch, and 15.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ----\n",
    "# ## D3. 把 NeRF depth 反投影成世界坐标点云\n",
    "\n",
    "# %%\n",
    "def load_nerf_depth(frame_id: int):\n",
    "    \"\"\"读取 NeRF 渲染出的 depth 图，假设命名为 0000.png, 0001.png, ...\"\"\"\n",
    "    fname = f\"{frame_id:04d}.png\"\n",
    "    d_path = depth_dir / fname\n",
    "    if not d_path.exists():\n",
    "        return None\n",
    "\n",
    "    # 假设是 16-bit PNG，存的是 depth_m * scale\n",
    "    depth_raw = np.array(Image.open(d_path))\n",
    "    if depth_raw.dtype == np.uint16:\n",
    "        # 假设最大值映射到 10m（你也可以根据 ns-render 文档调整）\n",
    "        depth_m = depth_raw.astype(np.float32) / 65535.0 * 10.0\n",
    "    else:\n",
    "        depth_m = depth_raw.astype(np.float32)\n",
    "    return depth_m  # (H, W)\n",
    "\n",
    "\n",
    "# 预生成一个 pinhole 像素网格\n",
    "u = torch.arange(W_p, device=device).view(1, -1).expand(H_p, W_p)\n",
    "v = torch.arange(H_p, device=device).view(-1, 1).expand(H_p, W_p)\n",
    "\n",
    "x_cam = (u - cx) / fx\n",
    "y_cam = (v - cy) / fy\n",
    "ones  = torch.ones_like(x_cam)\n",
    "dirs_cam_pinhole = torch.stack([x_cam, y_cam, ones], dim=-1)  # (H_p, W_p, 3)\n",
    "dirs_cam_pinhole = dirs_cam_pinhole / torch.linalg.norm(dirs_cam_pinhole, dim=-1, keepdim=True)\n",
    "\n",
    "print(\"dirs_cam_pinhole:\", dirs_cam_pinhole.shape)\n",
    "\n",
    "\n",
    "# %%\n",
    "def nerf_points_world_from_depth(frame_id: int, max_points: int = 20000):\n",
    "    \"\"\"\n",
    "    从第 frame_id 帧的 NeRF depth 图生成世界坐标点云。\n",
    "    \"\"\"\n",
    "    depth_m = load_nerf_depth(frame_id)\n",
    "    if depth_m is None:\n",
    "        return None\n",
    "\n",
    "    depth_m = torch.from_numpy(depth_m).to(device=device, dtype=torch.float32)  # (H_p, W_p)\n",
    "\n",
    "    # 有效像素：深度>0\n",
    "    valid = depth_m > 0\n",
    "    if valid.sum() == 0:\n",
    "        return None\n",
    "\n",
    "    d_valid = depth_m[valid]                             # (Nv,)\n",
    "    dirs_valid = dirs_cam_pinhole[valid]                 # (Nv,3)\n",
    "\n",
    "    print(f\"DEBUG: dirs_valid shape: {dirs_valid.shape}\")\n",
    "    print(f\"DEBUG: d_valid shape before: {d_valid.shape}\")\n",
    "    print(f\"DEBUG: d_valid unsqueezed: {d_valid.unsqueeze(-1).shape}\")\n",
    "\n",
    "    pts_cam = dirs_valid * d_valid.unsqueeze(-1)         # (Nv,3)\n",
    "\n",
    "    # cam2world pose\n",
    "    T_c2w = poses_c2w[frame_id]                          # (4,4)\n",
    "    R = T_c2w[:3, :3]\n",
    "    t = T_c2w[:3, 3]\n",
    "\n",
    "    pts_world = (R @ pts_cam.T + t.view(3, 1)).T         # (Nv,3)\n",
    "\n",
    "    # 随机下采样\n",
    "    if max_points is not None and pts_world.shape[0] > max_points:\n",
    "        idx = torch.randperm(pts_world.shape[0], device=device)[:max_points]\n",
    "        pts_world = pts_world[idx]\n",
    "\n",
    "    return pts_world\n",
    "\n",
    "\n",
    "# %%\n",
    "# 聚合若干帧的 NeRF 点云（可以先只用前 N 帧测试）\n",
    "nerf_points_list = []\n",
    "max_frames = num_frames  # 或先 100\n",
    "for fid in tqdm(range(max_frames), desc=\"Collect NeRF points\"):\n",
    "    pts_w = nerf_points_world_from_depth(fid, max_points=10000)\n",
    "    if pts_w is None:\n",
    "        continue\n",
    "    nerf_points_list.append(pts_w.cpu())\n",
    "\n",
    "if len(nerf_points_list) == 0:\n",
    "    raise RuntimeError(\"No NeRF points collected, please check depth rendering.\")\n",
    "nerf_points = torch.cat(nerf_points_list, dim=0).numpy().astype(np.float32)\n",
    "print(\"NeRF points:\", nerf_points.shape)\n",
    "\n",
    "# 保存成 PLY\n",
    "nerf_ply_path = STAGE_A_ROOT / \"nerf_pointcloud_depth.ply\"\n",
    "pcd_nerf = o3d.geometry.PointCloud()\n",
    "pcd_nerf.points = o3d.utility.Vector3dVector(nerf_points)\n",
    "o3d.io.write_point_cloud(str(nerf_ply_path), pcd_nerf)\n",
    "print(\"Saved NeRF point cloud to:\", nerf_ply_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c68fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ----\n",
    "# ## D4. 准备 GT surface 点云（coverage_mesh.obj）\n",
    "\n",
    "# %%\n",
    "gt_mesh_path = RAW_ROOT / \"coverage_mesh.obj\"\n",
    "assert gt_mesh_path.exists(), f\"coverage_mesh.obj not found: {gt_mesh_path}\"\n",
    "\n",
    "mesh_gt = o3d.io.read_triangle_mesh(str(gt_mesh_path))\n",
    "mesh_gt.compute_vertex_normals()\n",
    "print(mesh_gt)\n",
    "\n",
    "# 从 mesh 采样点云\n",
    "num_gt_samples = 200000\n",
    "pcd_gt = mesh_gt.sample_points_uniformly(number_of_points=num_gt_samples)\n",
    "gt_points = np.asarray(pcd_gt.points).astype(np.float32)\n",
    "print(\"GT sampled points:\", gt_points.shape)\n",
    "\n",
    "gt_ply_path = STAGE_A_ROOT / \"gt_surface_points.ply\"\n",
    "o3d.io.write_point_cloud(str(gt_ply_path), pcd_gt)\n",
    "print(\"Saved GT sampled points to:\", gt_ply_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764d3c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ----\n",
    "# ## D5. 最近邻距离 & Chamfer 风格评估（NeRF vs GT）\n",
    "\n",
    "# %%\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def nn_stats(src_pts: np.ndarray, dst_pts: np.ndarray, k: int = 1):\n",
    "    \"\"\"\n",
    "    对于 src 中每个点，找 dst 中最近邻距离。\n",
    "    返回 distances (N,) 和一些统计值。\n",
    "    \"\"\"\n",
    "    nbrs = NearestNeighbors(n_neighbors=k, algorithm=\"kd_tree\").fit(dst_pts)\n",
    "    dists, _ = nbrs.kneighbors(src_pts)\n",
    "    dists = dists[:, 0]  # (N,)\n",
    "    stats = {\n",
    "        \"mean\": float(dists.mean()),\n",
    "        \"median\": float(np.median(dists)),\n",
    "        \"95%\": float(np.percentile(dists, 95)),\n",
    "        \"max\": float(dists.max()),\n",
    "    }\n",
    "    return dists, stats\n",
    "\n",
    "# 为了算得快一点，可选 subsample\n",
    "max_nerf_eval = 200000\n",
    "if nerf_points.shape[0] > max_nerf_eval:\n",
    "    idx = np.random.choice(nerf_points.shape[0], max_nerf_eval, replace=False)\n",
    "    nerf_eval = nerf_points[idx]\n",
    "else:\n",
    "    nerf_eval = nerf_points\n",
    "\n",
    "max_gt_eval = 200000\n",
    "if gt_points.shape[0] > max_gt_eval:\n",
    "    idx = np.random.choice(gt_points.shape[0], max_gt_eval, replace=False)\n",
    "    gt_eval = gt_points[idx]\n",
    "else:\n",
    "    gt_eval = gt_points\n",
    "\n",
    "print(\"NeRF eval pts:\", nerf_eval.shape)\n",
    "print(\"GT   eval pts:\", gt_eval.shape)\n",
    "\n",
    "# NeRF -> GT\n",
    "d_nerf2gt, stats_nerf2gt = nn_stats(nerf_eval, gt_eval)\n",
    "\n",
    "# GT -> NeRF\n",
    "d_gt2nerf, stats_gt2nerf = nn_stats(gt_eval, nerf_eval)\n",
    "\n",
    "print(\"NeRF → GT stats (meters):\")\n",
    "for k, v in stats_nerf2gt.items():\n",
    "    print(f\"  {k:6s}: {v}\")\n",
    "\n",
    "print(\"\\nGT → NeRF stats (meters):\")\n",
    "for k, v in stats_gt2nerf.items():\n",
    "    print(f\"  {k:6s}: {v}\")\n",
    "\n",
    "chamfer_like = stats_nerf2gt[\"mean\"] + stats_gt2nerf[\"mean\"]\n",
    "print(f\"\\nChamfer-like distance (mean n2g + mean g2n): {chamfer_like}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc48395",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ----\n",
    "# ## D6. 画直方图 + 三维可视化（风格和 Stage C 保持一致）\n",
    "\n",
    "# %%\n",
    "# 直方图（单位改成毫米更直观）\n",
    "plt.figure(figsize=(12, 4))\n",
    "bins = 80\n",
    "\n",
    "plt.hist(d_nerf2gt * 1000.0, bins=bins, alpha=0.7, label=\"NeRF → GT\")\n",
    "plt.hist(d_gt2nerf * 1000.0, bins=bins, alpha=0.7, label=\"GT → NeRF\")\n",
    "plt.xlabel(\"NN distance [mm]\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"NN Distance Distributions: NeRF vs GT\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# 三维散点（随机抽一点点看形状）\n",
    "N_vis = 60000\n",
    "if nerf_points.shape[0] > N_vis:\n",
    "    idx = np.random.choice(nerf_points.shape[0], N_vis, replace=False)\n",
    "    nerf_vis = nerf_points[idx]\n",
    "else:\n",
    "    nerf_vis = nerf_points\n",
    "\n",
    "if gt_points.shape[0] > N_vis:\n",
    "    idx = np.random.choice(gt_points.shape[0], N_vis, replace=False)\n",
    "    gt_vis = gt_points[idx]\n",
    "else:\n",
    "    gt_vis = gt_points\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "ax.scatter(gt_vis[:, 0], gt_vis[:, 1], gt_vis[:, 2], s=0.5, alpha=0.4, label=\"GT\")\n",
    "ax.scatter(nerf_vis[:, 0], nerf_vis[:, 1], nerf_vis[:, 2], s=0.5, alpha=0.4, label=\"NeRF\")\n",
    "\n",
    "ax.set_xlabel(\"X (m)\")\n",
    "ax.set_ylabel(\"Y (m)\")\n",
    "ax.set_zlabel(\"Z (m)\")\n",
    "ax.set_title(\"Point clouds: GT vs NeRF (subsampled)\")\n",
    "ax.legend()\n",
    "ax.set_box_aspect([1, 1, 1])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdteacher-ns",
   "language": "python",
   "name": "cdteacher-ns"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
