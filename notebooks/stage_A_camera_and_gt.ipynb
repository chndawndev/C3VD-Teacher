{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccdbe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "RAW_ROOT = \"/data1_ycao/chua/projects/cdTeacher/data_raw/c1_descending_t2_v2\"\n",
    "OUT_ROOT = \"/data1_ycao/chua/projects/cdTeacher/outputs/stage_A/c1_descending_t2_v2\"\n",
    "\n",
    "os.makedirs(OUT_ROOT, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e4685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 来自你之前的相机内参\n",
    "omni_intrinsics = {\n",
    "    \"width\": 1350,\n",
    "    \"height\": 1080,\n",
    "    \"cx\": 677.739464094188,\n",
    "    \"cy\": 543.057997844875,\n",
    "    \"a0\": 767.733695862103,\n",
    "    \"a1\": 0.0,\n",
    "    \"a2\": -0.000592506426558248,\n",
    "    \"a3\": -2.69440266600040e-07,\n",
    "    \"a4\": -2.16380341010063e-10,\n",
    "    \"c\": 0.9999,\n",
    "    \"d\": 1.10e-4,\n",
    "    \"e\": -1.83e-4,\n",
    "}\n",
    "\n",
    "with open(os.path.join(OUT_ROOT, \"camera_omni.json\"), \"w\") as f:\n",
    "    json.dump(omni_intrinsics, f, indent=2)\n",
    "print(\"Saved omni intrinsics to camera_omni.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91936662",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OmniCamera(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Scaramuzza-style omnidirectional camera (pixel -> ray in camera frame).\n",
    "    坐标系约定:\n",
    "      - 像素: u 向右, v 向下\n",
    "      - 相机系: +x 向右, +y 向下, +z 沿视线方向\n",
    "    \"\"\"\n",
    "    def __init__(self, intrinsics):\n",
    "        super().__init__()\n",
    "        self.width = intrinsics[\"width\"]\n",
    "        self.height = intrinsics[\"height\"]\n",
    "        self.cx = intrinsics[\"cx\"]\n",
    "        self.cy = intrinsics[\"cy\"]\n",
    "        self.c = intrinsics[\"c\"]\n",
    "        self.d = intrinsics[\"d\"]\n",
    "        self.e = intrinsics[\"e\"]\n",
    "        # 多项式系数 pol(r) = a0 + a1*r + ... (cam2world 用)\n",
    "        self.register_buffer(\n",
    "            \"pol\",\n",
    "            torch.tensor([\n",
    "                intrinsics[\"a0\"],\n",
    "                intrinsics[\"a1\"],\n",
    "                intrinsics[\"a2\"],\n",
    "                intrinsics[\"a3\"],\n",
    "                intrinsics[\"a4\"],\n",
    "            ], dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "        # 预算 affine 矩阵的逆: [x';y'] = A^{-1} * ([u-cx; v-cy])\n",
    "        A = torch.tensor([[self.c, self.d],\n",
    "                          [self.e, 1.0]], dtype=torch.float32)\n",
    "        A_inv = torch.inverse(A)\n",
    "        self.register_buffer(\"A_inv\", A_inv)\n",
    "\n",
    "    def forward(self, u, v):\n",
    "        \"\"\"\n",
    "        u, v: (...,) 像素坐标 (float32)，可以是任意 shape\n",
    "        返回: (..., 3) 单位方向向量 (x,y,z) in camera frame\n",
    "        \"\"\"\n",
    "        # 保证 tensor\n",
    "        u = torch.as_tensor(u, dtype=torch.float32, device=self.pol.device)\n",
    "        v = torch.as_tensor(v, dtype=torch.float32, device=self.pol.device)\n",
    "\n",
    "        # 平移到主点\n",
    "        x_img = u - self.cx\n",
    "        y_img = v - self.cy\n",
    "\n",
    "        # 逆 affine 校正\n",
    "        # [x'; y'] = A_inv @ [x_img; y_img]\n",
    "        x_prime = self.A_inv[0, 0] * x_img + self.A_inv[0, 1] * y_img\n",
    "        y_prime = self.A_inv[1, 0] * x_img + self.A_inv[1, 1] * y_img\n",
    "\n",
    "        r = torch.sqrt(x_prime**2 + y_prime**2)  # 半径\n",
    "\n",
    "        # 计算 z = pol(r)\n",
    "        # pol(r) = a0 + a1*r + a2*r^2 + ...\n",
    "        # 用 Horner 法或直接 sum\n",
    "        powers = torch.stack([r**i for i in range(self.pol.shape[0])], dim=0)  # (deg+1, ...)\n",
    "        z = (self.pol.view(-1, *([1] * (powers.ndim - 1))) * powers).sum(dim=0)\n",
    "\n",
    "        # 方向向量 (x', y', z)，再单位化\n",
    "        # 注意: 如果 r=0，则 x'=y'=0，此时方向就是 (0,0,1)\n",
    "        dir_cam = torch.stack([x_prime, y_prime, z], dim=-1)\n",
    "        dir_norm = dir_cam / torch.linalg.norm(dir_cam, dim=-1, keepdim=True).clamp(min=1e-9)\n",
    "        return dir_norm\n",
    "\n",
    "omni_cam = OmniCamera(omni_intrinsics).to(device)\n",
    "print(\"Omni camera model ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8582d5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_path = os.path.join(RAW_ROOT, \"pose.txt\")\n",
    "poses_list = []\n",
    "\n",
    "with open(pose_path, \"r\") as f:\n",
    "    for line_idx, line in enumerate(f):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        # 支持逗号和空格：把逗号先替换成空格，再 split\n",
    "        parts = [p for p in line.replace(\",\", \" \").split() if p]\n",
    "        if len(parts) != 16:\n",
    "            raise ValueError(\n",
    "                f\"Line {line_idx} in pose.txt has {len(parts)} values, expected 16. Line content: {line}\"\n",
    "            )\n",
    "\n",
    "        vals = np.array(parts, dtype=np.float32)\n",
    "        mat_raw = vals.reshape(4, 4)      # 这是 T^T 的形状\n",
    "        T = mat_raw.T                     # 转置成标准 T_cam2world\n",
    "\n",
    "        # ✅ 把平移从 mm → m，和 depth_m 对齐\n",
    "        T[0:3, 3] /= 1000.0\n",
    "\n",
    "        poses_list.append(T)\n",
    "\n",
    "poses_cam2world = torch.from_numpy(np.stack(poses_list, axis=0))  # (N,4,4)\n",
    "print(\"Loaded poses:\", poses_cam2world.shape)\n",
    "print(\"Pose[0]:\\n\", poses_cam2world[0])\n",
    "print(\"torch norm of translation vector in pose[0]:\",\n",
    "      torch.linalg.norm(poses_cam2world[0, :3, 3]))\n",
    "norms = torch.linalg.norm(poses_cam2world[:, :3, 3], dim=1)\n",
    "print(\"min / max / mean translation norm (m):\",\n",
    "      norms.min().item(), norms.max().item(), norms.mean().item())\n",
    "R0 = poses_cam2world[0, :3, :3]\n",
    "print(\"R0^T R0 ≈\\n\", (R0.T @ R0))\n",
    "print(\"det(R0) =\", torch.linalg.det(R0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4368b4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_depth_and_mask(frame_id: int):\n",
    "    fname = f\"{frame_id:04d}\"\n",
    "    depth_path = os.path.join(RAW_ROOT, \"depth\", f\"{fname}_depth.tiff\")\n",
    "    occ_path   = os.path.join(RAW_ROOT, \"occlusions\", f\"{fname}_occlusion.png\")\n",
    "\n",
    "    depth_img = np.array(Image.open(depth_path))  # 原始是 uint16\n",
    "    occ_img   = np.array(Image.open(occ_path))    # uint8\n",
    "\n",
    "    # ⚠️ 关键改动：不要用 uint16，改成 int32\n",
    "    depth_raw = torch.from_numpy(depth_img.astype(np.int32)).to(device)\n",
    "    occ_u8    = torch.from_numpy(occ_img.astype(np.uint8)).to(device)\n",
    "\n",
    "    # 0~65535 → 0~0.1 m (0~100mm)\n",
    "    depth_m = depth_raw.to(torch.float32) / 65535.0 * 0.1\n",
    "\n",
    "    # 有效像素：有深度 && 没 occlusion\n",
    "    valid = (depth_raw > 0) & (occ_u8 == 0)\n",
    "\n",
    "    return depth_m, valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff45f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = omni_intrinsics[\"height\"]\n",
    "W = omni_intrinsics[\"width\"]\n",
    "\n",
    "# 生成像素坐标网格 (H,W)\n",
    "u_coords = torch.arange(W, device=device).view(1, -1).expand(H, W)  # v 行, u 列\n",
    "v_coords = torch.arange(H, device=device).view(-1, 1).expand(H, W)\n",
    "\n",
    "# 预计算像素对应的射线方向（在 Camera Frame）\n",
    "with torch.no_grad():\n",
    "    dirs_cam = omni_cam(u_coords, v_coords)  # (H,W,3)\n",
    "print(\"dirs_cam shape:\", dirs_cam.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2552577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_points_world(frame_id: int, max_points: int = None):\n",
    "    \"\"\"\n",
    "    返回某一帧的世界系点云 (N,3)\n",
    "    max_points: 为了控制内存，可以随机 subsample\n",
    "    \"\"\"\n",
    "    depth_m, valid = load_depth_and_mask(frame_id)   # (H,W)\n",
    "    dirs = dirs_cam  # (H,W,3)\n",
    "\n",
    "    # 有效像素\n",
    "    valid_mask = valid & (depth_m > 0)\n",
    "    if valid_mask.sum() == 0:\n",
    "        return None\n",
    "\n",
    "    depth_z = depth_m  # 沿 z 轴的深度\n",
    "\n",
    "    # 提取有效像素的射线方向和 depth_z\n",
    "    depth_z_valid = depth_z[valid_mask]  # (Nv,)\n",
    "    dirs_valid = dirs[valid_mask]        # (Nv,3)\n",
    "\n",
    "    # 避免除以 0\n",
    "    dz = dirs_valid[:, 2].clamp(min=1e-6)\n",
    "    scale = depth_z_valid / dz          # (Nv,)\n",
    "\n",
    "    pts_cam = dirs_valid * scale.unsqueeze(-1)  # (Nv,3)\n",
    "\n",
    "    # 取该帧的 pose\n",
    "    T = poses_cam2world[frame_id].to(device)    # (4,4)\n",
    "    R = T[:3, :3]\n",
    "    t = T[:3, 3]\n",
    "\n",
    "    pts_world = (R @ pts_cam.T + t.view(3, 1)).T  # (Nv,3)\n",
    "\n",
    "    # 可选 subsample，避免点数太多\n",
    "    if max_points is not None and pts_world.shape[0] > max_points:\n",
    "        idx = torch.randperm(pts_world.shape[0], device=device)[:max_points]\n",
    "        pts_world = pts_world[idx]\n",
    "\n",
    "    return pts_world\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d3d4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "\n",
    "def plot_camera_trajectory(poses_cam2world, num_frames=10, stride=1):\n",
    "    \"\"\"\n",
    "    简单的相机轨迹可视化工具。\n",
    "    - poses_cam2world: (N,4,4) torch.Tensor\n",
    "    \"\"\"\n",
    "    # 全部先变成 numpy，避免 torch 和 matplotlib 打架\n",
    "    poses_np = poses_cam2world.detach().cpu().numpy()  # (N,4,4)\n",
    "    N = poses_np.shape[0]\n",
    "    num_frames = min(num_frames, N)\n",
    "\n",
    "    # 相机中心 C = t\n",
    "    C = poses_np[:num_frames, :3, 3]  # (num_frames, 3)\n",
    "\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "    # 轨迹线\n",
    "    ax.plot(C[:, 0], C[:, 1], C[:, 2], \"-o\", markersize=3, label=\"camera centers\")\n",
    "\n",
    "    # 画若干帧的小坐标轴\n",
    "    axis_len = 0.02  # m\n",
    "    for i in range(0, num_frames, stride):\n",
    "        T = poses_np[i]\n",
    "        R = T[:3, :3]   # (3,3)\n",
    "        t = T[:3, 3]    # (3,)\n",
    "\n",
    "        x_axis = t + R[:, 0] * axis_len\n",
    "        y_axis = t + R[:, 1] * axis_len\n",
    "        z_axis = t + R[:, 2] * axis_len\n",
    "\n",
    "        # 这里都用纯 float / list，彻底避免 torch\n",
    "        ax.plot([t[0], x_axis[0]], [t[1], x_axis[1]], [t[2], x_axis[2]], \"r-\")\n",
    "        ax.plot([t[0], y_axis[0]], [t[1], y_axis[1]], [t[2], y_axis[2]], \"g-\")\n",
    "        ax.plot([t[0], z_axis[0]], [t[1], z_axis[1]], [t[2], z_axis[2]], \"b-\")\n",
    "\n",
    "    ax.set_xlabel(\"X (m)\")\n",
    "    ax.set_ylabel(\"Y (m)\")\n",
    "    ax.set_zlabel(\"Z (m)\")\n",
    "    ax.set_title(f\"Camera trajectory (first {num_frames} frames)\")\n",
    "\n",
    "    ax.legend()\n",
    "    ax.set_box_aspect([1, 1, 1])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_camera_trajectory(poses_cam2world, num_frames=123, stride=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e19aa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ply(path, points: np.ndarray):\n",
    "    \"\"\"\n",
    "    points: (N,3) float32 numpy array\n",
    "    \"\"\"\n",
    "    N = points.shape[0]\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(\"ply\\n\")\n",
    "        f.write(\"format ascii 1.0\\n\")\n",
    "        f.write(f\"element vertex {N}\\n\")\n",
    "        f.write(\"property float x\\n\")\n",
    "        f.write(\"property float y\\n\")\n",
    "        f.write(\"property float z\\n\")\n",
    "        f.write(\"end_header\\n\")\n",
    "        for p in points:\n",
    "            f.write(f\"{p[0]} {p[1]} {p[2]}\\n\")\n",
    "    print(f\"Saved PLY with {N} points to {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb60933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_points = []\n",
    "\n",
    "num_frames = poses_cam2world.shape[0]\n",
    "print(\"Total frames:\", num_frames)\n",
    "\n",
    "# 先用少数 frame 热身，比如前 20 帧\n",
    "max_frames = min(num_frames, 123)\n",
    "\n",
    "for fid in range(max_frames):\n",
    "    pts_w = frame_points_world(fid, max_points=5000)  # 每帧最多 5000 点，避免炸显存\n",
    "    if pts_w is None:\n",
    "        continue\n",
    "    all_points.append(pts_w.cpu())\n",
    "    print(f\"Frame {fid:04d}: {pts_w.shape[0]} pts\")\n",
    "\n",
    "if len(all_points) == 0:\n",
    "    print(\"No points collected, check masks / depth.\")\n",
    "else:\n",
    "    all_points_tensor = torch.cat(all_points, dim=0)  # (N_total,3)\n",
    "    pts_np = all_points_tensor.numpy().astype(np.float32)\n",
    "    ply_path = os.path.join(OUT_ROOT, \"gt_pointcloud_partial.ply\")\n",
    "    write_ply(ply_path, pts_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47e5051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "ply_path = os.path.join(OUT_ROOT, \"gt_pointcloud_partial.ply\")\n",
    "\n",
    "pcd = o3d.io.read_point_cloud(ply_path)\n",
    "print(pcd)\n",
    "print(\"Point count:\", np.asarray(pcd.points).shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b4200e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "\n",
    "pts = np.asarray(pcd.points)\n",
    "print(\"Loaded points:\", pts.shape)\n",
    "\n",
    "# 随机下采样一点，避免点太多渲染太慢\n",
    "max_points = 60000\n",
    "if pts.shape[0] > max_points:\n",
    "    idx = np.random.choice(pts.shape[0], max_points, replace=False)\n",
    "    pts_vis = pts[idx]\n",
    "else:\n",
    "    pts_vis = pts\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "ax.scatter(pts_vis[:, 0], pts_vis[:, 1], pts_vis[:, 2], s=0.5, alpha=0.5)\n",
    "\n",
    "ax.set_xlabel(\"X (m)\")\n",
    "ax.set_ylabel(\"Y (m)\")\n",
    "ax.set_zlabel(\"Z (m)\")\n",
    "ax.set_title(\"GT point cloud (subsampled)\")\n",
    "\n",
    "ax.set_box_aspect([1, 1, 1])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d1fdaa",
   "metadata": {},
   "source": [
    "following code description\n",
    "\n",
    "定义虚拟 pinhole 相机（分辨率 + FOV + fx/fy/cx/cy）\n",
    "\n",
    "用 fisheye 像素 → 射线 → pinhole 像素 做 forward splat 重采样\n",
    "\n",
    "导出 undistorted RGB \n",
    "\n",
    "生成 Nerfstudio 兼容的 transforms.json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da201723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# 原始 fisheye 分辨率\n",
    "H_f = omni_intrinsics[\"height\"]\n",
    "W_f = omni_intrinsics[\"width\"]\n",
    "\n",
    "# 目标 pinhole 分辨率（可改）\n",
    "W_p = 960\n",
    "H_p = 720\n",
    "\n",
    "# 目标 pinhole FOV（水平）\n",
    "fov_deg = 90.0\n",
    "fov_rad = math.radians(fov_deg)\n",
    "\n",
    "# fx = (W/2) / tan(FOV/2)\n",
    "fx = (W_p / 2.0) / math.tan(fov_rad / 2.0)\n",
    "fy = fx  # 保持方像素\n",
    "\n",
    "cx_p = W_p / 2.0\n",
    "cy_p = H_p / 2.0\n",
    "\n",
    "pinhole_intrinsics = {\n",
    "    \"width\": W_p,\n",
    "    \"height\": H_p,\n",
    "    \"fx\": fx,\n",
    "    \"fy\": fy,\n",
    "    \"cx\": cx_p,\n",
    "    \"cy\": cy_p,\n",
    "    \"fov_deg\": fov_deg,\n",
    "}\n",
    "\n",
    "print(\"Pinhole intrinsics:\", pinhole_intrinsics)\n",
    "\n",
    "# 输出目录\n",
    "UNDIST_ROOT = os.path.join(OUT_ROOT, \"undistorted\")\n",
    "UNDIST_RGB_ROOT = os.path.join(UNDIST_ROOT, \"rgb\")\n",
    "os.makedirs(UNDIST_RGB_ROOT, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(UNDIST_ROOT, \"camera_pinhole.json\"), \"w\") as f:\n",
    "    json.dump(pinhole_intrinsics, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9502288",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = omni_intrinsics[\"height\"]\n",
    "W = omni_intrinsics[\"width\"]\n",
    "\n",
    "u_coords = torch.arange(W, device=device).view(1, -1).expand(H, W)\n",
    "v_coords = torch.arange(H, device=device).view(-1, 1).expand(H, W)\n",
    "\n",
    "with torch.no_grad():\n",
    "    dirs_cam = omni_cam(u_coords, v_coords)  # (H,W,3)\n",
    "print(\"dirs_cam:\", dirs_cam.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9898b541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirs_cam: (H_f, W_f, 3)\n",
    "x_f = dirs_cam[..., 0]  # (H_f, W_f)\n",
    "y_f = dirs_cam[..., 1]\n",
    "z_f = dirs_cam[..., 2].clamp(min=1e-6)  # 避免除以 0\n",
    "\n",
    "# 对每个 fisheye 像素，计算它投到 pinhole 上的位置\n",
    "u_p_map = fx * (x_f / z_f) + cx_p\n",
    "v_p_map = fy * (y_f / z_f) + cy_p\n",
    "\n",
    "print(\"u_p_map range:\", u_p_map.min().item(), u_p_map.max().item())\n",
    "print(\"v_p_map range:\", v_p_map.min().item(), v_p_map.max().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9672fa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisheye_to_pinhole_rgb(rgb_fisheye: torch.Tensor,\n",
    "                           u_p_map: torch.Tensor,\n",
    "                           v_p_map: torch.Tensor,\n",
    "                           W_p: int,\n",
    "                           H_p: int):\n",
    "    \"\"\"\n",
    "    rgb_fisheye: (H_f, W_f, 3), float32, [0,1]\n",
    "    u_p_map, v_p_map: (H_f, W_f), 每个 fisheye 像素在 pinhole 平面上的浮点坐标\n",
    "    返回:\n",
    "      rgb_pinhole: (H_p, W_p, 3), float32, [0,1]\n",
    "      weight: (H_p, W_p), float32, 每个像素累计权重（用于 Debug）\n",
    "    \"\"\"\n",
    "    device = rgb_fisheye.device\n",
    "    H_f, W_f, _ = rgb_fisheye.shape\n",
    "\n",
    "    # 展平成一维，方便 scatter\n",
    "    u_flat = u_p_map.reshape(-1)\n",
    "    v_flat = v_p_map.reshape(-1)\n",
    "    rgb_flat = rgb_fisheye.reshape(-1, 3)\n",
    "\n",
    "    # 只保留 z>0 且投影落在 pinhole 范围附近的点（多给 1 像素边界）\n",
    "    valid = (\n",
    "        (u_flat >= -1) & (u_flat <= W_p) &\n",
    "        (v_flat >= -1) & (v_flat <= H_p)\n",
    "    )\n",
    "    u_flat = u_flat[valid]\n",
    "    v_flat = v_flat[valid]\n",
    "    rgb_flat = rgb_flat[valid]\n",
    "\n",
    "    # 计算周围的四个像素\n",
    "    u0 = torch.floor(u_flat).to(torch.long)\n",
    "    v0 = torch.floor(v_flat).to(torch.long)\n",
    "    du = u_flat - u0.to(torch.float32)\n",
    "    dv = v_flat - v0.to(torch.float32)\n",
    "\n",
    "    # 四个角： (u0,v0), (u0+1,v0), (u0,v0+1), (u0+1,v0+1)\n",
    "    u1 = u0 + 1\n",
    "    v1 = v0 + 1\n",
    "\n",
    "    # 权重\n",
    "    w00 = (1 - du) * (1 - dv)\n",
    "    w10 = du * (1 - dv)\n",
    "    w01 = (1 - du) * dv\n",
    "    w11 = du * dv\n",
    "\n",
    "    # 初始化输出\n",
    "    rgb_out = torch.zeros((H_p, W_p, 3), dtype=torch.float32, device=device)\n",
    "    w_out = torch.zeros((H_p, W_p), dtype=torch.float32, device=device)\n",
    "\n",
    "    def accumulate(u, v, w):\n",
    "        # 过滤在图像范围内的\n",
    "        mask = (u >= 0) & (u < W_p) & (v >= 0) & (v < H_p) & (w > 0)\n",
    "        if mask.sum() == 0:\n",
    "            return\n",
    "        u_sel = u[mask]\n",
    "        v_sel = v[mask]\n",
    "        w_sel = w[mask]\n",
    "        rgb_sel = rgb_flat[mask]\n",
    "\n",
    "        idx = v_sel * W_p + u_sel  # flatten 索引\n",
    "\n",
    "        # 对 RGB 进行 scatter_add\n",
    "        rgb_out_flat = rgb_out.reshape(-1, 3)\n",
    "        w_out_flat = w_out.reshape(-1)\n",
    "\n",
    "        rgb_out_flat.index_add_(0, idx, rgb_sel * w_sel.unsqueeze(-1))\n",
    "        w_out_flat.index_add_(0, idx, w_sel)\n",
    "\n",
    "    accumulate(u0, v0, w00)\n",
    "    accumulate(u1, v0, w10)\n",
    "    accumulate(u0, v1, w01)\n",
    "    accumulate(u1, v1, w11)\n",
    "\n",
    "    # 归一化：除以权重，防止除以 0\n",
    "    w_out_clamped = w_out.clamp(min=1e-6).unsqueeze(-1)\n",
    "    rgb_norm = rgb_out / w_out_clamped\n",
    "\n",
    "    return rgb_norm, w_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370edd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def load_rgb_frame(frame_id: int):\n",
    "    fname = f\"{frame_id:04d}\"\n",
    "    rgb_path = os.path.join(RAW_ROOT, \"rgb\", f\"{fname}.png\")\n",
    "    img = Image.open(rgb_path).convert(\"RGB\")\n",
    "    arr = np.array(img)  # (H_f, W_f, 3), uint8\n",
    "    # [0,255] -> [0,1]\n",
    "    rgb = torch.from_numpy(arr).to(device=device, dtype=torch.float32) / 255.0\n",
    "    return rgb\n",
    "\n",
    "num_frames = poses_cam2world.shape[0]\n",
    "print(\"Total frames:\", num_frames)\n",
    "\n",
    "# 你可以先热身跑前 N 帧\n",
    "max_frames = num_frames  # 或者先 50\n",
    "for fid in tqdm(range(max_frames), desc=\"Undistorting frames\"):\n",
    "    rgb_fisheye = load_rgb_frame(fid)  # (H_f, W_f, 3)\n",
    "\n",
    "    rgb_pinhole, w_p = fisheye_to_pinhole_rgb(\n",
    "        rgb_fisheye, u_p_map, v_p_map, W_p, H_p\n",
    "    )\n",
    "\n",
    "    # 转成 uint8 保存\n",
    "    rgb_np = (rgb_pinhole.clamp(0.0, 1.0).cpu().numpy() * 255.0).astype(np.uint8)\n",
    "    img_out = Image.fromarray(rgb_np, mode=\"RGB\")\n",
    "\n",
    "    out_path = os.path.join(UNDIST_RGB_ROOT, f\"{fid:04d}.png\")\n",
    "    img_out.save(out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91cb491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_4x4(T: torch.Tensor):\n",
    "    \"\"\"\n",
    "    T: (N,4,4) 或 (...,4,4)，camera-to-world\n",
    "    返回: 同形状的 world-to-camera\n",
    "    \"\"\"\n",
    "    # 旋转和平移\n",
    "    R = T[..., :3, :3]          # (...,3,3)\n",
    "    t = T[..., :3, 3]           # (...,3)\n",
    "\n",
    "    R_inv = R.transpose(-1, -2)               # R^T\n",
    "    t_inv = -(R_inv @ t.unsqueeze(-1)).squeeze(-1)  # -R^T t\n",
    "\n",
    "    # 初始化全 0，再填旋转 & 平移 & 最后一行\n",
    "    T_inv = torch.zeros_like(T)\n",
    "    T_inv[..., :3, :3] = R_inv\n",
    "    T_inv[..., :3, 3]  = t_inv\n",
    "    T_inv[..., 3, 3]   = 1.0\n",
    "\n",
    "    return T_inv\n",
    "\n",
    "poses_c2w = poses_cam2world.to(torch.float32).to(device)\n",
    "poses_w2c = invert_4x4(poses_c2w).cpu().numpy()  # (N,4,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c97e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# 直接使用 cam2world（原始 pose），只确保是 float32 + CPU\n",
    "poses_c2w = poses_cam2world.to(torch.float32).cpu().numpy()  # (N,4,4)\n",
    "\n",
    "ns_transform = {\n",
    "    \"camera_model\": \"PINHOLE\",\n",
    "    \"w\": W_p,\n",
    "    \"h\": H_p,\n",
    "    \"fl_x\": float(fx),\n",
    "    \"fl_y\": float(fy),\n",
    "    \"cx\": float(cx_p),\n",
    "    \"cy\": float(cy_p),\n",
    "    \"frames\": [],\n",
    "}\n",
    "\n",
    "for fid in range(num_frames):\n",
    "    T_c2w = poses_c2w[fid]  # (4,4), camera-to-world\n",
    "\n",
    "    frame = {\n",
    "        \"file_path\": f\"./undistorted/rgb/{fid:04d}.png\",\n",
    "        \"transform_matrix\": T_c2w.tolist(),\n",
    "    }\n",
    "    ns_transform[\"frames\"].append(frame)\n",
    "\n",
    "out_path = os.path.join(OUT_ROOT, \"transforms.json\")\n",
    "with open(out_path, \"w\") as f:\n",
    "    json.dump(ns_transform, f, indent=2)\n",
    "\n",
    "print(\"Wrote Nerfstudio transforms to\", out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb0fc82",
   "metadata": {},
   "source": [
    "可以直接在 OUT_ROOT 目录里运行：\n",
    "\n",
    "cd /data1_ycao/chua/projects/cdTeacher/outputs/stage_A/c1_descending_t2_v2\n",
    "\n",
    "只看轨迹：\n",
    "ns-viewer --data . --data-parser-name nerfstudio-data\n",
    "\n",
    "训练：\n",
    "ns-train nerfacto --data . --pipeline.datamanager.data.parser_name nerfstudio-data\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdteacher-ns",
   "language": "python",
   "name": "cdteacher-ns"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
